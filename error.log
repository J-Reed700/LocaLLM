{"timestamp": "2024-12-01T00:32:52.375339+00:00", "level": null, "name": "opentelemetry.sdk.trace.export", "message": "Exception while exporting Span batch.", "pathname": "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py", "lineno": 362, "funcName": "_export_batch", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 6137917440, "threadName": "OtelBatchSpanProcessor", "process": 67838, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 199, in _new_conn\n    sock = connection.create_connection(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 953, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1252, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1012, in _send_output\n    self.send(msg)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 952, in send\n    self.connect()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 279, in connect\n    self.sock = self._new_conn()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 206, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPConnection object at 0x10c3505e0>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10c3505e0>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n    return self._export_serialized_spans(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n    resp = self._export(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n    return self._session.post(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/requests/__init__.py\", line 180, in instrumented_send\n    return wrapped_send(self, request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10c3505e0>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:33:07.341446+00:00", "level": null, "name": "opentelemetry.sdk.trace.export", "message": "Exception while exporting Span batch.", "pathname": "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py", "lineno": 362, "funcName": "_export_batch", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 6137917440, "threadName": "OtelBatchSpanProcessor", "process": 67838, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 199, in _new_conn\n    sock = connection.create_connection(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 953, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1252, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1012, in _send_output\n    self.send(msg)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 952, in send\n    self.connect()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 279, in connect\n    self.sock = self._new_conn()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 206, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPConnection object at 0x10c3a8790>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10c3a8790>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n    return self._export_serialized_spans(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n    resp = self._export(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n    return self._session.post(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/requests/__init__.py\", line 180, in instrumented_send\n    return wrapped_send(self, request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10c3a8790>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:35:22.666541+00:00", "level": null, "name": "opentelemetry.sdk.trace.export", "message": "Exception while exporting Span batch.", "pathname": "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py", "lineno": 362, "funcName": "_export_batch", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 6171652096, "threadName": "OtelBatchSpanProcessor", "process": 68047, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 199, in _new_conn\n    sock = connection.create_connection(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 953, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1252, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1012, in _send_output\n    self.send(msg)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 952, in send\n    self.connect()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 279, in connect\n    self.sock = self._new_conn()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 206, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPConnection object at 0x114593f10>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x114593f10>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n    return self._export_serialized_spans(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n    resp = self._export(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n    return self._session.post(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/requests/__init__.py\", line 180, in instrumented_send\n    return wrapped_send(self, request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x114593f10>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:36:27.160519+00:00", "level": null, "name": "opentelemetry.sdk.trace.export", "message": "Exception while exporting Span batch.", "pathname": "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py", "lineno": 362, "funcName": "_export_batch", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 6347976704, "threadName": "OtelBatchSpanProcessor", "process": 68211, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 199, in _new_conn\n    sock = connection.create_connection(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 953, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1252, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1012, in _send_output\n    self.send(msg)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 952, in send\n    self.connect()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 279, in connect\n    self.sock = self._new_conn()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 206, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPConnection object at 0x10e60e640>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10e60e640>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n    return self._export_serialized_spans(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n    resp = self._export(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n    return self._session.post(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/requests/__init__.py\", line 180, in instrumented_send\n    return wrapped_send(self, request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10e60e640>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:36:32.156728+00:00", "level": null, "name": "opentelemetry.sdk.trace.export", "message": "Exception while exporting Span batch.", "pathname": "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py", "lineno": 362, "funcName": "_export_batch", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 6347976704, "threadName": "OtelBatchSpanProcessor", "process": 68211, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 199, in _new_conn\n    sock = connection.create_connection(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 953, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1252, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1012, in _send_output\n    self.send(msg)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 952, in send\n    self.connect()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 279, in connect\n    self.sock = self._new_conn()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connection.py\", line 206, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPConnection object at 0x10e78be50>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10e78be50>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n    return self._export_serialized_spans(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n    resp = self._export(serialized_data)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n    return self._session.post(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/requests/__init__.py\", line 180, in instrumented_send\n    return wrapped_send(self, request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=4318): Max retries exceeded with url: /v1/traces (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x10e78be50>: Failed to resolve 'host.docker.internal' ([Errno 8] nodename nor servname provided, or not known)\"))", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:37:36.512345+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "88a342b710966d4f", "otelTraceID": "6431408511aca1015aac69936ce270c1", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:37:36.523906+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "88a342b710966d4f", "otelTraceID": "6431408511aca1015aac69936ce270c1", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T00:45:00.978331+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "0b7945b9527198bc", "otelTraceID": "95a925c178b478a979c1950ee8e3dd73", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:45:00.979487+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "0b7945b9527198bc", "otelTraceID": "95a925c178b478a979c1950ee8e3dd73", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T00:45:02.691819+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "e7c3e22c1f7404b9", "otelTraceID": "54c2470d5ef4619ba44d7269e6574a6b", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:45:02.692595+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "e7c3e22c1f7404b9", "otelTraceID": "54c2470d5ef4619ba44d7269e6574a6b", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T00:45:08.600580+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "273d3e028b91de58", "otelTraceID": "30003d36b5c57d78f2e71514563c0b1e", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:45:08.601334+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "273d3e028b91de58", "otelTraceID": "30003d36b5c57d78f2e71514563c0b1e", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T00:45:14.158853+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "3218cb02969a3e78", "otelTraceID": "c457253729bbaccd3ff761e3f1decdd6", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:45:14.159968+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "3218cb02969a3e78", "otelTraceID": "c457253729bbaccd3ff761e3f1decdd6", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T00:46:25.163327+00:00", "level": null, "name": "root", "message": "Error in http_request: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 111, in receive\n    return self.receive_nowait()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 106, in receive_nowait\n    raise WouldBlock\nanyio.WouldBlock\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 124, in receive\n    return receiver.item\nAttributeError: 'MemoryObjectItemReceiver' object has no attribute 'item'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 157, in call_next\n    message = await recv_stream.receive()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 291, in app\n    solved_result = await solve_dependencies(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 638, in solve_dependencies\n    solved = await call(**solved_result.values)\n  File \"/Users/joshreed/Code/LocalGPU/src/dependencies/container.py\", line 80, in get_llm_service\n    return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 227, in __init__\n    self.handler = self.model_factory.get_handler(self.model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 205, in get_handler\n    return TextModelHandler(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 72, in __init__\n    super().__init__(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 41, in __init__\n    self._setup_model_parameters()\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 83, in _setup_model_parameters\n    self.model_discovery = ModelDiscoveryService()\nTypeError: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "otelSpanID": "989f7562e6dec64c", "otelTraceID": "19653c406329d849cbe16d85f5cccc19", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "__init__() missing 2 required positional arguments: 'db_context' and 'storage'", "error_type": "TypeError", "function": "http_request", "request_path": "http://localhost:8080/generate/text/", "request_method": "POST", "stack_trace": [["<frame at 0x11ad0e880, file '/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py', line 47, code _handle_request>", "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py", 28, "_handle_request", ["            response = await call_next(request)\n"], 0], ["<frame at 0x11ad0fc80, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 163, code call_next>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 163, "call_next", ["                    raise app_exc\n"], 0], ["<frame at 0x11ad108f0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 151, code coro>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 149, "coro", ["                        await self.app(scope, receive_or_disconnect, send_no_error)\n"], 0], ["<frame at 0x11ad10b00, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py', line 804, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py", 743, "__call__", ["                await self.app(scope, otel_receive, otel_send)\n"], 0], ["<frame at 0x11a8ee5e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 20, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 20, "__call__", ["                await responder(scope, receive, send)\n"], 0], ["<frame at 0x11a8edbe0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 39, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 39, "__call__", ["            await self.app(scope, receive, self.send_with_gzip)\n"], 0], ["<frame at 0x11a8eddd0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py', line 93, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py", 93, "__call__", ["        await self.simple_response(scope, receive, send, request_headers=headers)\n"], 0], ["<frame at 0x11af6b3e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py', line 144, code simple_response>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py", 144, "simple_response", ["        await self.app(scope, receive, send)\n"], 0], ["<frame at 0x11a8f15b0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py', line 62, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py", 62, "__call__", ["        await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n"], 0], ["<frame at 0x10ec3e090, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10ec3e090, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x11a8f1780, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 715, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 715, "__call__", ["        await self.middleware_stack(scope, receive, send)\n"], 0], ["<frame at 0x11ab05f40, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 735, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 735, "app", ["                await route.handle(scope, receive, send)\n"], 0], ["<frame at 0x11a8ee7c0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 288, code handle>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 288, "handle", ["            await self.app(scope, receive, send)\n"], 0], ["<frame at 0x11a8ee9a0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 76, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 76, "app", ["        await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n"], 0], ["<frame at 0x10ec41e70, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10ec41e70, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x11a8f1950, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 73, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 73, "app", ["            response = await f(request)\n"], 0], ["<frame at 0x11ab063a0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py', line 346, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py", 291, "app", ["                solved_result = await solve_dependencies(\n"], 0], ["<frame at 0x10ec3cd90, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py', line 638, code solve_dependencies>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py", 638, "solve_dependencies", ["            solved = await call(**solved_result.values)\n"], 0], ["<frame at 0x109647a60, file '/Users/joshreed/Code/LocalGPU/src/dependencies/container.py', line 80, code get_llm_service>", "/Users/joshreed/Code/LocalGPU/src/dependencies/container.py", 80, "get_llm_service", ["    return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n"], 0], ["<frame at 0x10ed36120, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 227, code __init__>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 227, "__init__", ["        self.handler = self.model_factory.get_handler(self.model_config)\n"], 0], ["<frame at 0x118decea0, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 205, code get_handler>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 205, "get_handler", ["            return TextModelHandler(model_config)\n"], 0], ["<frame at 0x11fc04180, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 72, code __init__>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 72, "__init__", ["        super().__init__(model_config)\n"], 0], ["<frame at 0x10aaf8460, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 41, code __init__>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 41, "__init__", ["        self._setup_model_parameters()\n"], 0], ["<frame at 0x10aafd670, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 83, code _setup_model_parameters>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 83, "_setup_model_parameters", ["        self.model_discovery = ModelDiscoveryService()\n"], 0]]}
{"timestamp": "2024-12-01T00:46:25.165453+00:00", "level": null, "name": "websrc.api.middleware.error_handlers", "message": "Unhandled exception: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/error_handlers.py", "lineno": 120, "funcName": "generic_exception_handler", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n  |     response_sent.set()\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 763, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    |     response_sent.set()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    |     return await self._handle_request(request, call_next, span)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    |     response = await call_next(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    |     await self.app(scope, otel_receive, otel_send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    |     await self.app(scope, receive, self.send_with_gzip)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 291, in app\n    |     solved_result = await solve_dependencies(\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 638, in solve_dependencies\n    |     solved = await call(**solved_result.values)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/dependencies/container.py\", line 80, in get_llm_service\n    |     return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 227, in __init__\n    |     self.handler = self.model_factory.get_handler(self.model_config)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 205, in get_handler\n    |     return TextModelHandler(model_config)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 72, in __init__\n    |     super().__init__(model_config)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 41, in __init__\n    |     self._setup_model_parameters()\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 83, in _setup_model_parameters\n    |     self.model_discovery = ModelDiscoveryService()\n    | TypeError: __init__() missing 2 required positional arguments: 'db_context' and 'storage'\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    response_sent.set()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    return await self._handle_request(request, call_next, span)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 291, in app\n    solved_result = await solve_dependencies(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 638, in solve_dependencies\n    solved = await call(**solved_result.values)\n  File \"/Users/joshreed/Code/LocalGPU/src/dependencies/container.py\", line 80, in get_llm_service\n    return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 227, in __init__\n    self.handler = self.model_factory.get_handler(self.model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 205, in get_handler\n    return TextModelHandler(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 72, in __init__\n    super().__init__(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 41, in __init__\n    self._setup_model_parameters()\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 83, in _setup_model_parameters\n    self.model_discovery = ModelDiscoveryService()\nTypeError: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:46:34.514405+00:00", "level": null, "name": "root", "message": "Error in http_request: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 111, in receive\n    return self.receive_nowait()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 106, in receive_nowait\n    raise WouldBlock\nanyio.WouldBlock\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 124, in receive\n    return receiver.item\nAttributeError: 'MemoryObjectItemReceiver' object has no attribute 'item'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 157, in call_next\n    message = await recv_stream.receive()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 291, in app\n    solved_result = await solve_dependencies(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 638, in solve_dependencies\n    solved = await call(**solved_result.values)\n  File \"/Users/joshreed/Code/LocalGPU/src/dependencies/container.py\", line 80, in get_llm_service\n    return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 227, in __init__\n    self.handler = self.model_factory.get_handler(self.model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 205, in get_handler\n    return TextModelHandler(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 72, in __init__\n    super().__init__(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 41, in __init__\n    self._setup_model_parameters()\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 83, in _setup_model_parameters\n    self.model_discovery = ModelDiscoveryService()\nTypeError: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "otelSpanID": "8a9460c18c0f13ea", "otelTraceID": "e5743cfc14bce285e8a3a58b30b61e1c", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "__init__() missing 2 required positional arguments: 'db_context' and 'storage'", "error_type": "TypeError", "function": "http_request", "request_path": "http://localhost:8080/generate/text/", "request_method": "POST", "stack_trace": [["<frame at 0x1096468e0, file '/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py', line 47, code _handle_request>", "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py", 28, "_handle_request", ["            response = await call_next(request)\n"], 0], ["<frame at 0x10aad00c0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 163, code call_next>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 163, "call_next", ["                    raise app_exc\n"], 0], ["<frame at 0x10aaf9f60, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 151, code coro>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 149, "coro", ["                        await self.app(scope, receive_or_disconnect, send_no_error)\n"], 0], ["<frame at 0x119a45b70, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py', line 804, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py", 743, "__call__", ["                await self.app(scope, otel_receive, otel_send)\n"], 0], ["<frame at 0x1291f79a0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 20, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 20, "__call__", ["                await responder(scope, receive, send)\n"], 0], ["<frame at 0x11fd80040, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 39, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 39, "__call__", ["            await self.app(scope, receive, self.send_with_gzip)\n"], 0], ["<frame at 0x11fd80420, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py', line 93, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py", 93, "__call__", ["        await self.simple_response(scope, receive, send, request_headers=headers)\n"], 0], ["<frame at 0x12a987040, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py', line 144, code simple_response>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py", 144, "simple_response", ["        await self.app(scope, receive, send)\n"], 0], ["<frame at 0x12a987210, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py', line 62, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py", 62, "__call__", ["        await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n"], 0], ["<frame at 0x119a41c10, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x119a41c10, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x12a9873e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 715, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 715, "__call__", ["        await self.middleware_stack(scope, receive, send)\n"], 0], ["<frame at 0x119a39a20, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 735, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 735, "app", ["                await route.handle(scope, receive, send)\n"], 0], ["<frame at 0x1291907c0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 288, code handle>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 288, "handle", ["            await self.app(scope, receive, send)\n"], 0], ["<frame at 0x129190b80, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 76, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 76, "app", ["        await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n"], 0], ["<frame at 0x10ec3ade0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10ec3ade0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x12a9875b0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 73, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 73, "app", ["            response = await f(request)\n"], 0], ["<frame at 0x10ec3dc40, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py', line 346, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py", 291, "app", ["                solved_result = await solve_dependencies(\n"], 0], ["<frame at 0x10ec40dc0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py', line 638, code solve_dependencies>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py", 638, "solve_dependencies", ["            solved = await call(**solved_result.values)\n"], 0], ["<frame at 0x118deeb30, file '/Users/joshreed/Code/LocalGPU/src/dependencies/container.py', line 80, code get_llm_service>", "/Users/joshreed/Code/LocalGPU/src/dependencies/container.py", 80, "get_llm_service", ["    return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n"], 0], ["<frame at 0x118de9990, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 227, code __init__>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 227, "__init__", ["        self.handler = self.model_factory.get_handler(self.model_config)\n"], 0], ["<frame at 0x118df1a40, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 205, code get_handler>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 205, "get_handler", ["            return TextModelHandler(model_config)\n"], 0], ["<frame at 0x1292bc1f0, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 72, code __init__>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 72, "__init__", ["        super().__init__(model_config)\n"], 0], ["<frame at 0x1292bca60, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 41, code __init__>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 41, "__init__", ["        self._setup_model_parameters()\n"], 0], ["<frame at 0x12907d5e0, file '/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py', line 83, code _setup_model_parameters>", "/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py", 83, "_setup_model_parameters", ["        self.model_discovery = ModelDiscoveryService()\n"], 0]]}
{"timestamp": "2024-12-01T00:46:34.521329+00:00", "level": null, "name": "websrc.api.middleware.error_handlers", "message": "Unhandled exception: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/error_handlers.py", "lineno": 120, "funcName": "generic_exception_handler", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n  |     response_sent.set()\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 763, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    |     response_sent.set()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    |     return await self._handle_request(request, call_next, span)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    |     response = await call_next(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    |     await self.app(scope, otel_receive, otel_send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    |     await self.app(scope, receive, self.send_with_gzip)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 291, in app\n    |     solved_result = await solve_dependencies(\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 638, in solve_dependencies\n    |     solved = await call(**solved_result.values)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/dependencies/container.py\", line 80, in get_llm_service\n    |     return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 227, in __init__\n    |     self.handler = self.model_factory.get_handler(self.model_config)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 205, in get_handler\n    |     return TextModelHandler(model_config)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 72, in __init__\n    |     super().__init__(model_config)\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 41, in __init__\n    |     self._setup_model_parameters()\n    |   File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 83, in _setup_model_parameters\n    |     self.model_discovery = ModelDiscoveryService()\n    | TypeError: __init__() missing 2 required positional arguments: 'db_context' and 'storage'\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    response_sent.set()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    return await self._handle_request(request, call_next, span)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 291, in app\n    solved_result = await solve_dependencies(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 638, in solve_dependencies\n    solved = await call(**solved_result.values)\n  File \"/Users/joshreed/Code/LocalGPU/src/dependencies/container.py\", line 80, in get_llm_service\n    return LLMGenerate(get_model_factory(), conversation_context, settings_service)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 227, in __init__\n    self.handler = self.model_factory.get_handler(self.model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 205, in get_handler\n    return TextModelHandler(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 72, in __init__\n    super().__init__(model_config)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 41, in __init__\n    self._setup_model_parameters()\n  File \"/Users/joshreed/Code/LocalGPU/src/services/llm_generate.py\", line 83, in _setup_model_parameters\n    self.model_discovery = ModelDiscoveryService()\nTypeError: __init__() missing 2 required positional arguments: 'db_context' and 'storage'", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:52:29.209671+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "52ac68d949c84fbd", "otelTraceID": "37b5c6ad8d196782e2b0cc73fff4cdaf", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:52:29.210729+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "52ac68d949c84fbd", "otelTraceID": "37b5c6ad8d196782e2b0cc73fff4cdaf", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T00:52:51.411633+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "df3036fdbdc360de", "otelTraceID": "a4196b25aa5f73f94dea13754ef3dc4e", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T00:52:51.412845+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "df3036fdbdc360de", "otelTraceID": "a4196b25aa5f73f94dea13754ef3dc4e", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:13:47.628386+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "76eaca34006fc0da", "otelTraceID": "1be9fe383dd10944ebdeefd91b0f0c91", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:13:47.629657+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "76eaca34006fc0da", "otelTraceID": "1be9fe383dd10944ebdeefd91b0f0c91", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:13:50.572155+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "974912ed9058ce60", "otelTraceID": "45315add16025952657e2eada1767a7d", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:13:50.572973+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "974912ed9058ce60", "otelTraceID": "45315add16025952657e2eada1767a7d", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:16:12.104982+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "867d7047aad193bc", "otelTraceID": "74b150681827c0121559119c4cc677a7", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:16:12.105919+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 68307, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "867d7047aad193bc", "otelTraceID": "74b150681827c0121559119c4cc677a7", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:16:48.204496+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "a68eb1891995f477", "otelTraceID": "c6d67814fac1f78ff028f54a8f8272d4", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:16:48.213482+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "a68eb1891995f477", "otelTraceID": "c6d67814fac1f78ff028f54a8f8272d4", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:20:01.981017+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "420921342be8cce7", "otelTraceID": "d959fb54b7eabe94e82ea206e6eb0951", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:20:01.981878+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "420921342be8cce7", "otelTraceID": "d959fb54b7eabe94e82ea206e6eb0951", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:20:03.851725+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "2ff9e28cd703d862", "otelTraceID": "3d94a8b6877d5a198e8f92f739ae2927", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:20:03.853313+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "2ff9e28cd703d862", "otelTraceID": "3d94a8b6877d5a198e8f92f739ae2927", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:21:48.347516+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "9701f82b0508ac65", "otelTraceID": "6c40bd005af84981ce516ebca37a40c2", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:21:48.348284+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "9701f82b0508ac65", "otelTraceID": "6c40bd005af84981ce516ebca37a40c2", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:21:51.516325+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "30aa6bbac00d6c88", "otelTraceID": "8b24128f5fa3048b8a7bd5a8dd98c17f", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:21:51.516907+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "30aa6bbac00d6c88", "otelTraceID": "8b24128f5fa3048b8a7bd5a8dd98c17f", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:21:58.344068+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "5e12ac0ae1fcb519", "otelTraceID": "b3aeee5bae6e19875a7bbd97ea3b1b45", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:21:58.344883+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "5e12ac0ae1fcb519", "otelTraceID": "b3aeee5bae6e19875a7bbd97ea3b1b45", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:22:00.908494+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "868925fdd73ce337", "otelTraceID": "d91db99fc74639c93859ddc3b3af5ed3", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:22:00.909184+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "868925fdd73ce337", "otelTraceID": "d91db99fc74639c93859ddc3b3af5ed3", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:22:13.488935+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "7f7ae224a819990e", "otelTraceID": "ab356e38715bfb2d0b19939028f53f88", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:22:13.489829+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "7f7ae224a819990e", "otelTraceID": "ab356e38715bfb2d0b19939028f53f88", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:22:15.189557+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "2cb032d4403a2b0c", "otelTraceID": "89c51108b9575317bb29cc22bc2131c5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:22:15.190549+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "2cb032d4403a2b0c", "otelTraceID": "89c51108b9575317bb29cc22bc2131c5", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:23:01.680380+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "b33c77bbc526fc69", "otelTraceID": "48e6197d8184105577399034650777d2", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:23:01.682638+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "b33c77bbc526fc69", "otelTraceID": "48e6197d8184105577399034650777d2", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:10.368814+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "c2db5fc881377113", "otelTraceID": "85376ec9007832085e2c0c1321bec07c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:10.370136+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "c2db5fc881377113", "otelTraceID": "85376ec9007832085e2c0c1321bec07c", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:15.219162+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "fe74862c6e4a9b77", "otelTraceID": "a03c169e65edacb88bf7b94e4baa19ec", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:15.220003+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "fe74862c6e4a9b77", "otelTraceID": "a03c169e65edacb88bf7b94e4baa19ec", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:16.472383+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "be5370303dec006b", "otelTraceID": "f52206bae10a7df657165665c23e4e5f", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:16.473078+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "be5370303dec006b", "otelTraceID": "f52206bae10a7df657165665c23e4e5f", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:23.856151+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "7ca3f580070b8ba8", "otelTraceID": "96fd7f4bfdf7920fb7289246172f385f", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:23.856861+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "7ca3f580070b8ba8", "otelTraceID": "96fd7f4bfdf7920fb7289246172f385f", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:26.361396+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "64c910b4f987b71b", "otelTraceID": "62c1607318602c94bc1ae3965c5cf2eb", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:26.361986+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "64c910b4f987b71b", "otelTraceID": "62c1607318602c94bc1ae3965c5cf2eb", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:30.413287+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "9b61d576583d2199", "otelTraceID": "5aae1ca753da5f45f55f2f4ef48ea8f1", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:30.414031+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "9b61d576583d2199", "otelTraceID": "5aae1ca753da5f45f55f2f4ef48ea8f1", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:24:34.718450+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "e576bddd11efe0ff", "otelTraceID": "7a4af0ffb44f2fc56ad7b05f1616f79d", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:24:34.719044+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "e576bddd11efe0ff", "otelTraceID": "7a4af0ffb44f2fc56ad7b05f1616f79d", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:25:25.491642+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "95f6016578653d70", "otelTraceID": "47d4d91a8af6d02e9187a2a3d9672394", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:25:25.492831+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 71299, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    local_models = await self._get_local_models(model_type)\nAttributeError: 'ModelDiscoveryService' object has no attribute '_get_local_models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "otelSpanID": "95f6016578653d70", "otelTraceID": "47d4d91a8af6d02e9187a2a3d9672394", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_get_local_models'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:28:17.673036+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 109, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "otelSpanID": "2b67735e53cfad1a", "otelTraceID": "d0d2937e8fdea2f6ca85d7fe65c6cfa3", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:28:17.674194+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "otelSpanID": "2b67735e53cfad1a", "otelTraceID": "d0d2937e8fdea2f6ca85d7fe65c6cfa3", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:28:17.688592+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 81, in _get_remote_models\n    models = await self.hf_api.list_models(\nTypeError: object generator can't be used in 'await' expression\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: object generator can't be used in 'await' expression", "otelSpanID": "2b67735e53cfad1a", "otelTraceID": "d0d2937e8fdea2f6ca85d7fe65c6cfa3", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: object generator can't be used in 'await' expression", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:28:56.154767+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 109, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "otelSpanID": "a59d3ea8f737b0f2", "otelTraceID": "fbe5ae0f5b2855a2d3de84bcf2e6ab36", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:28:56.155401+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "otelSpanID": "a59d3ea8f737b0f2", "otelTraceID": "fbe5ae0f5b2855a2d3de84bcf2e6ab36", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:28:56.156010+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 81, in _get_remote_models\n    models = await self.hf_api.list_models(\nTypeError: object generator can't be used in 'await' expression\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: object generator can't be used in 'await' expression", "otelSpanID": "a59d3ea8f737b0f2", "otelTraceID": "fbe5ae0f5b2855a2d3de84bcf2e6ab36", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: object generator can't be used in 'await' expression", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:29:48.304724+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 109, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "otelSpanID": "c32ac43e0100b267", "otelTraceID": "f2f7a5b9d4693320b1576cfdbc185fda", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:29:48.305312+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "otelSpanID": "c32ac43e0100b267", "otelTraceID": "f2f7a5b9d4693320b1576cfdbc185fda", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:29:48.305992+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: object generator can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72115, "processName": "SpawnProcess-4", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 81, in _get_remote_models\n    models = await self.hf_api.list_models(\nTypeError: object generator can't be used in 'await' expression\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: object generator can't be used in 'await' expression", "otelSpanID": "c32ac43e0100b267", "otelTraceID": "f2f7a5b9d4693320b1576cfdbc185fda", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: object generator can't be used in 'await' expression", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:30:42.491036+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 109, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72296, "processName": "SpawnProcess-5", "extra_info": null, "otelSpanID": "aab215ce6f32bde4", "otelTraceID": "cdfc13152ba5f8479b849554e6c768b2", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:30:42.491936+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72296, "processName": "SpawnProcess-5", "extra_info": null, "otelSpanID": "aab215ce6f32bde4", "otelTraceID": "cdfc13152ba5f8479b849554e6c768b2", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:30:42.507159+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72296, "processName": "SpawnProcess-5", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 98, in _get_remote_models\n    is_downloaded=await self.is_model_downloaded(model.id),\nAttributeError: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "otelSpanID": "aab215ce6f32bde4", "otelTraceID": "cdfc13152ba5f8479b849554e6c768b2", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:34:55.028390+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: object Future can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 109, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72631, "processName": "SpawnProcess-8", "extra_info": null, "otelSpanID": "05ed617cc40e04b6", "otelTraceID": "be3754ba94f7d9cb8f22352aa283f4af", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:34:55.029098+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: object Future can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72631, "processName": "SpawnProcess-8", "extra_info": null, "otelSpanID": "05ed617cc40e04b6", "otelTraceID": "be3754ba94f7d9cb8f22352aa283f4af", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:34:55.056775+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: object Future can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72631, "processName": "SpawnProcess-8", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 81, in _get_remote_models\n    models = await self._executor.submit(self.hf_api.list_models,\nTypeError: object Future can't be used in 'await' expression\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: object Future can't be used in 'await' expression", "otelSpanID": "05ed617cc40e04b6", "otelTraceID": "be3754ba94f7d9cb8f22352aa283f4af", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: object Future can't be used in 'await' expression", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:35:01.387872+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: object Future can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 109, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72631, "processName": "SpawnProcess-8", "extra_info": null, "otelSpanID": "36e7fed7264cbd24", "otelTraceID": "09cbb25225ec83bc446c2ae11cdc410c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:35:01.388332+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: object Future can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72631, "processName": "SpawnProcess-8", "extra_info": null, "otelSpanID": "36e7fed7264cbd24", "otelTraceID": "09cbb25225ec83bc446c2ae11cdc410c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:35:01.388858+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: object Future can't be used in 'await' expression", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 72631, "processName": "SpawnProcess-8", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 81, in _get_remote_models\n    models = await self._executor.submit(self.hf_api.list_models,\nTypeError: object Future can't be used in 'await' expression\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: object Future can't be used in 'await' expression", "otelSpanID": "36e7fed7264cbd24", "otelTraceID": "09cbb25225ec83bc446c2ae11cdc410c", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: object Future can't be used in 'await' expression", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:35:34.022968+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 113, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73495, "processName": "SpawnProcess-9", "extra_info": null, "otelSpanID": "48a4dc3b0c4d70e6", "otelTraceID": "30185226c288dc70b7bec248f9f5a8b5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:35:34.023665+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73495, "processName": "SpawnProcess-9", "extra_info": null, "otelSpanID": "48a4dc3b0c4d70e6", "otelTraceID": "30185226c288dc70b7bec248f9f5a8b5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:35:34.042287+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73495, "processName": "SpawnProcess-9", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 102, in _get_remote_models\n    is_downloaded=await self.is_model_downloaded(model.id),\nAttributeError: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "otelSpanID": "48a4dc3b0c4d70e6", "otelTraceID": "30185226c288dc70b7bec248f9f5a8b5", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute 'is_model_downloaded'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:37:15.532077+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'NoneType' object has no attribute 'get'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 113, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73636, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "1954cb32f767fc31", "otelTraceID": "29be1c0116938600f95d9a6b7956ed3c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:37:15.532935+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'NoneType' object has no attribute 'get'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73636, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "1954cb32f767fc31", "otelTraceID": "29be1c0116938600f95d9a6b7956ed3c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:37:15.553850+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'NoneType' object has no attribute 'get'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73636, "processName": "SpawnProcess-10", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 104, in _get_remote_models\n    requirements=self._get_model_requirements(model.card_data),\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 119, in _get_model_requirements\n    \"memory\": card_data.get(\"memory_requirements\", \"Unknown\"),\nAttributeError: 'NoneType' object has no attribute 'get'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'NoneType' object has no attribute 'get'", "otelSpanID": "1954cb32f767fc31", "otelTraceID": "29be1c0116938600f95d9a6b7956ed3c", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'NoneType' object has no attribute 'get'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:37:20.709336+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'NoneType' object has no attribute 'get'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 113, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73636, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "ed7e48d0f6f60e3a", "otelTraceID": "2e3c1ccb6f078e2ad7cc0fd89c32e79c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:37:20.709963+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'NoneType' object has no attribute 'get'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73636, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "ed7e48d0f6f60e3a", "otelTraceID": "2e3c1ccb6f078e2ad7cc0fd89c32e79c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:37:20.711076+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'NoneType' object has no attribute 'get'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73636, "processName": "SpawnProcess-10", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 104, in _get_remote_models\n    requirements=self._get_model_requirements(model.card_data),\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 119, in _get_model_requirements\n    \"memory\": card_data.get(\"memory_requirements\", \"Unknown\"),\nAttributeError: 'NoneType' object has no attribute 'get'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'NoneType' object has no attribute 'get'", "otelSpanID": "ed7e48d0f6f60e3a", "otelTraceID": "2e3c1ccb6f078e2ad7cc0fd89c32e79c", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'NoneType' object has no attribute 'get'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:38:03.286654+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelInfo' object has no attribute 'description'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 113, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73766, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "72e5624a03e115ac", "otelTraceID": "cc409b3c57c5cf7c996e8ce1c490505a", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:38:03.287644+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelInfo' object has no attribute 'description'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73766, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "72e5624a03e115ac", "otelTraceID": "cc409b3c57c5cf7c996e8ce1c490505a", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:38:03.302869+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelInfo' object has no attribute 'description'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73766, "processName": "SpawnProcess-11", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 105, in _get_remote_models\n    description=model.description,\nAttributeError: 'ModelInfo' object has no attribute 'description'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelInfo' object has no attribute 'description'", "otelSpanID": "72e5624a03e115ac", "otelTraceID": "cc409b3c57c5cf7c996e8ce1c490505a", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelInfo' object has no attribute 'description'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:38:08.340798+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelInfo' object has no attribute 'description'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 113, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73766, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "ec7b7cee9a72ca43", "otelTraceID": "56ec4be9820a1ce843e90d84d4e95d1d", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:38:08.341650+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelInfo' object has no attribute 'description'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73766, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "ec7b7cee9a72ca43", "otelTraceID": "56ec4be9820a1ce843e90d84d4e95d1d", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:38:08.342414+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelInfo' object has no attribute 'description'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73766, "processName": "SpawnProcess-11", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 105, in _get_remote_models\n    description=model.description,\nAttributeError: 'ModelInfo' object has no attribute 'description'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelInfo' object has no attribute 'description'", "otelSpanID": "ec7b7cee9a72ca43", "otelTraceID": "56ec4be9820a1ce843e90d84d4e95d1d", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelInfo' object has no attribute 'description'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T01:38:44.560779+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'is_downloaded' is an invalid keyword argument for ModelInfo", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 113, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73830, "processName": "SpawnProcess-12", "extra_info": null, "otelSpanID": "499763f06b863c6b", "otelTraceID": "c02801d1a2f6b77858981a6f3531fa46", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:38:44.561261+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'is_downloaded' is an invalid keyword argument for ModelInfo", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 72, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73830, "processName": "SpawnProcess-12", "extra_info": null, "otelSpanID": "499763f06b863c6b", "otelTraceID": "c02801d1a2f6b77858981a6f3531fa46", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T01:38:44.600471+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'is_downloaded' is an invalid keyword argument for ModelInfo", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 73830, "processName": "SpawnProcess-12", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 66, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 96, in _get_remote_models\n    model_info = ModelInfo(\n  File \"<string>\", line 4, in __init__\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/sqlalchemy/orm/state.py\", line 572, in _initialize_instance\n    manager.dispatch.init_failure(self, args, kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/sqlalchemy/orm/state.py\", line 569, in _initialize_instance\n    manager.original_init(*mixed[1:], **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/sqlalchemy/orm/decl_base.py\", line 2177, in _declarative_constructor\n    raise TypeError(\nTypeError: 'is_downloaded' is an invalid keyword argument for ModelInfo\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'is_downloaded' is an invalid keyword argument for ModelInfo", "otelSpanID": "499763f06b863c6b", "otelTraceID": "c02801d1a2f6b77858981a6f3531fa46", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'is_downloaded' is an invalid keyword argument for ModelInfo", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:14:27.454469+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelInfo' object has no attribute 'model_id'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 75486, "processName": "SpawnProcess-36", "extra_info": null, "otelSpanID": "e17245e187538b87", "otelTraceID": "8ac39d9f7fcb7751d59b9b9c55a00f97", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:14:27.456131+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelInfo' object has no attribute 'model_id'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 75486, "processName": "SpawnProcess-36", "extra_info": null, "otelSpanID": "e17245e187538b87", "otelTraceID": "8ac39d9f7fcb7751d59b9b9c55a00f97", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:14:27.480885+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelInfo' object has no attribute 'model_id'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 75486, "processName": "SpawnProcess-36", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 152, in from_huggingface\n    model_id=model.model_id,\nAttributeError: 'ModelInfo' object has no attribute 'model_id'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelInfo' object has no attribute 'model_id'", "otelSpanID": "e17245e187538b87", "otelTraceID": "8ac39d9f7fcb7751d59b9b9c55a00f97", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelInfo' object has no attribute 'model_id'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:16:59.454593+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "otelSpanID": "6c1e807037cdf297", "otelTraceID": "48dfeb8ab80725afab009e0d3152da99", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:16:59.455260+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "otelSpanID": "6c1e807037cdf297", "otelTraceID": "48dfeb8ab80725afab009e0d3152da99", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:16:59.468445+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 153, in from_huggingface\n    name=model.card_data.model_name,\nAttributeError: 'NoneType' object has no attribute 'model_name'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'NoneType' object has no attribute 'model_name'", "otelSpanID": "6c1e807037cdf297", "otelTraceID": "48dfeb8ab80725afab009e0d3152da99", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'NoneType' object has no attribute 'model_name'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:17:26.890633+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "otelSpanID": "117a1ca8638b757a", "otelTraceID": "42f2f72b2a7a759278b43cd93af3e4ea", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:17:26.891031+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "otelSpanID": "117a1ca8638b757a", "otelTraceID": "42f2f72b2a7a759278b43cd93af3e4ea", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:17:26.891593+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 153, in from_huggingface\n    name=model.card_data.model_name,\nAttributeError: 'NoneType' object has no attribute 'model_name'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'NoneType' object has no attribute 'model_name'", "otelSpanID": "117a1ca8638b757a", "otelTraceID": "42f2f72b2a7a759278b43cd93af3e4ea", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'NoneType' object has no attribute 'model_name'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:17:45.993400+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "otelSpanID": "471dc8c566ca14ee", "otelTraceID": "26fa994bd31c473d8a32e4db63fe73d8", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:17:45.994479+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "otelSpanID": "471dc8c566ca14ee", "otelTraceID": "26fa994bd31c473d8a32e4db63fe73d8", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:17:45.995823+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'NoneType' object has no attribute 'model_name'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76681, "processName": "SpawnProcess-38", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 153, in from_huggingface\n    name=model.card_data.model_name,\nAttributeError: 'NoneType' object has no attribute 'model_name'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'NoneType' object has no attribute 'model_name'", "otelSpanID": "471dc8c566ca14ee", "otelTraceID": "26fa994bd31c473d8a32e4db63fe73d8", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'NoneType' object has no attribute 'model_name'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:18:38.631706+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76803, "processName": "SpawnProcess-40", "extra_info": null, "otelSpanID": "d32c840a47ca5bb5", "otelTraceID": "13e97a790dd38b97736e1bbc92723ec6", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:18:38.632569+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76803, "processName": "SpawnProcess-40", "extra_info": null, "otelSpanID": "d32c840a47ca5bb5", "otelTraceID": "13e97a790dd38b97736e1bbc92723ec6", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:18:38.648520+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76803, "processName": "SpawnProcess-40", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 184, in from_huggingface\n    updated_at=model.updated_at,\nAttributeError: 'ModelInfo' object has no attribute 'updated_at'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelInfo' object has no attribute 'updated_at'", "otelSpanID": "d32c840a47ca5bb5", "otelTraceID": "13e97a790dd38b97736e1bbc92723ec6", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelInfo' object has no attribute 'updated_at'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:19:20.114647+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76855, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "23635c79106803f6", "otelTraceID": "d3831ca7946dc54a2c416394134c7e49", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:19:20.115840+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76855, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "23635c79106803f6", "otelTraceID": "d3831ca7946dc54a2c416394134c7e49", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:19:20.131647+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 76855, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 184, in from_huggingface\n    updated_at=model.updated_at,\nAttributeError: 'ModelInfo' object has no attribute 'updated_at'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelInfo' object has no attribute 'updated_at'", "otelSpanID": "23635c79106803f6", "otelTraceID": "d3831ca7946dc54a2c416394134c7e49", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelInfo' object has no attribute 'updated_at'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:21:14.474116+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77018, "processName": "SpawnProcess-3", "extra_info": null, "otelSpanID": "7e13893c18abe2cc", "otelTraceID": "1f3cb312f2af1ca035da55638aa29da9", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:21:14.475437+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77018, "processName": "SpawnProcess-3", "extra_info": null, "otelSpanID": "7e13893c18abe2cc", "otelTraceID": "1f3cb312f2af1ca035da55638aa29da9", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:21:14.495272+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 'ModelInfo' object has no attribute 'updated_at'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77018, "processName": "SpawnProcess-3", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 184, in from_huggingface\n    updated_at=model.updated_at,\nAttributeError: 'ModelInfo' object has no attribute 'updated_at'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelInfo' object has no attribute 'updated_at'", "otelSpanID": "7e13893c18abe2cc", "otelTraceID": "1f3cb312f2af1ca035da55638aa29da9", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelInfo' object has no attribute 'updated_at'", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:22:16.131424+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error fetching remote models: 2 validation errors for ModelInfoDTO\nid\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Qwen/Qwen2.5-1.5B-Instruct', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nmodel_id\n  Field required [type=missing, input_value={'id': 'Qwen/Qwen2.5-1.5B...ag': 'text-generation'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 103, "funcName": "_get_remote_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77116, "processName": "SpawnProcess-5", "extra_info": null, "otelSpanID": "3ab997a7c2558abe", "otelTraceID": "3d65c4d0319559e70d7cfd738f7fc4c8", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:22:16.132474+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to fetch models: 2 validation errors for ModelInfoDTO\nid\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Qwen/Qwen2.5-1.5B-Instruct', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nmodel_id\n  Field required [type=missing, input_value={'id': 'Qwen/Qwen2.5-1.5B...ag': 'text-generation'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 73, "funcName": "get_available_models", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77116, "processName": "SpawnProcess-5", "extra_info": null, "otelSpanID": "3ab997a7c2558abe", "otelTraceID": "3d65c4d0319559e70d7cfd738f7fc4c8", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:22:16.153722+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.get_models: 500: 2 validation errors for ModelInfoDTO\nid\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Qwen/Qwen2.5-1.5B-Instruct', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nmodel_id\n  Field required [type=missing, input_value={'id': 'Qwen/Qwen2.5-1.5B...ag': 'text-generation'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77116, "processName": "SpawnProcess-5", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 40, in get_models\n    models = await model_service.get_available_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 67, in get_available_models\n    remote_models = await self._get_remote_models(model_type)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 97, in _get_remote_models\n    model_info = ModelInfoDTO.from_huggingface(model)\n  File \"/Users/joshreed/Code/LocalGPU/src/models/dto.py\", line 167, in from_huggingface\n    return cls(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/pydantic/main.py\", line 214, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 2 validation errors for ModelInfoDTO\nid\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Qwen/Qwen2.5-1.5B-Instruct', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nmodel_id\n  Field required [type=missing, input_value={'id': 'Qwen/Qwen2.5-1.5B...ag': 'text-generation'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 43, in get_models\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 2 validation errors for ModelInfoDTO\nid\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Qwen/Qwen2.5-1.5B-Instruct', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nmodel_id\n  Field required [type=missing, input_value={'id': 'Qwen/Qwen2.5-1.5B...ag': 'text-generation'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing", "otelSpanID": "3ab997a7c2558abe", "otelTraceID": "3d65c4d0319559e70d7cfd738f7fc4c8", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 2 validation errors for ModelInfoDTO\nid\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Qwen/Qwen2.5-1.5B-Instruct', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nmodel_id\n  Field required [type=missing, input_value={'id': 'Qwen/Qwen2.5-1.5B...ag': 'text-generation'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing", "error_type": "HTTPException", "function": "websrc.api.routes.models.get_models", "status_code": 500}
{"timestamp": "2024-12-01T02:23:17.097483+00:00", "level": null, "name": "root", "message": "Error in http_request: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53572, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53859, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53966, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54051, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54137, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54218, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54295, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54388, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54464, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54539, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54612, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54703, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54779, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54854, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54950, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55046, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55119, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55192, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55267, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55339, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77188, "processName": "SpawnProcess-6", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 111, in receive\n    return self.receive_nowait()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 106, in receive_nowait\n    raise WouldBlock\nanyio.WouldBlock\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 124, in receive\n    return receiver.item\nAttributeError: 'MemoryObjectItemReceiver' object has no attribute 'item'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 157, in call_next\n    message = await recv_stream.receive()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 327, in app\n    content = await serialize_response(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 176, in serialize_response\n    raise ResponseValidationError(\nfastapi.exceptions.ResponseValidationError: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53572, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53859, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53966, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54051, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54137, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54218, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54295, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54388, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54464, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54539, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54612, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54703, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54779, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54854, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54950, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55046, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55119, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55192, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55267, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55339, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "otelSpanID": "1d13b4da164d5550", "otelTraceID": "9980f59600c9b5a104b434e3ca81b9c0", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53572, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53859, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53966, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54051, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54137, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54218, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54295, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54388, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54464, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54539, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54612, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54703, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54779, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54854, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54950, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55046, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55119, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55192, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55267, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55339, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "error_type": "ResponseValidationError", "function": "http_request", "request_path": "http://localhost:8080/api/models/text", "request_method": "GET", "stack_trace": [["<frame at 0x10e60e970, file '/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py', line 47, code _handle_request>", "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py", 28, "_handle_request", ["            response = await call_next(request)\n"], 0], ["<frame at 0x10e305030, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 163, code call_next>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 163, "call_next", ["                    raise app_exc\n"], 0], ["<frame at 0x10e3056b0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 151, code coro>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 149, "coro", ["                        await self.app(scope, receive_or_disconnect, send_no_error)\n"], 0], ["<frame at 0x10e3058c0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py', line 804, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py", 743, "__call__", ["                await self.app(scope, otel_receive, otel_send)\n"], 0], ["<frame at 0x10e53d400, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 20, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 20, "__call__", ["                await responder(scope, receive, send)\n"], 0], ["<frame at 0x10e538dd0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 39, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 39, "__call__", ["            await self.app(scope, receive, self.send_with_gzip)\n"], 0], ["<frame at 0x10e540040, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py', line 85, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py", 85, "__call__", ["            await self.app(scope, receive, send)\n"], 0], ["<frame at 0x10e53e210, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py', line 62, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py", 62, "__call__", ["        await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n"], 0], ["<frame at 0x10e4053e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10e4053e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x10e53e3e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 715, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 715, "__call__", ["        await self.middleware_stack(scope, receive, send)\n"], 0], ["<frame at 0x10e306ae0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 735, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 735, "app", ["                await route.handle(scope, receive, send)\n"], 0], ["<frame at 0x10e53d5e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 288, code handle>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 288, "handle", ["            await self.app(scope, receive, send)\n"], 0], ["<frame at 0x10e53d7c0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 76, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 76, "app", ["        await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n"], 0], ["<frame at 0x10e208f60, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10e208f60, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x10e53e5b0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 73, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 73, "app", ["            response = await f(request)\n"], 0], ["<frame at 0x10e307380, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py', line 346, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py", 327, "app", ["                        content = await serialize_response(\n"], 0], ["<frame at 0x10e611650, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py', line 176, code serialize_response>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py", 176, "serialize_response", ["            raise ResponseValidationError(\n"], 0]]}
{"timestamp": "2024-12-01T02:23:17.108088+00:00", "level": null, "name": "websrc.api.middleware.error_handlers", "message": "Unhandled exception: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53572, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53859, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53966, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54051, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54137, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54218, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54295, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54388, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54464, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54539, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54612, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54703, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54779, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54854, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54950, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55046, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55119, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55192, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55267, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55339, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/error_handlers.py", "lineno": 120, "funcName": "generic_exception_handler", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77188, "processName": "SpawnProcess-6", "extra_info": null, "exc_info": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n  |     response_sent.set()\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 763, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    |     response_sent.set()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    |     return await self._handle_request(request, call_next, span)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    |     response = await call_next(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    |     await self.app(scope, otel_receive, otel_send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    |     await self.app(scope, receive, self.send_with_gzip)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 327, in app\n    |     content = await serialize_response(\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 176, in serialize_response\n    |     raise ResponseValidationError(\n    | fastapi.exceptions.ResponseValidationError: 20 validation errors:\n    |   {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53572, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53859, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53966, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54051, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54137, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54218, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54295, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54388, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54464, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54539, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54612, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54703, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54779, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54854, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54950, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55046, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55119, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55192, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55267, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55339, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    | \n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    response_sent.set()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    return await self._handle_request(request, call_next, span)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 327, in app\n    content = await serialize_response(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 176, in serialize_response\n    raise ResponseValidationError(\nfastapi.exceptions.ResponseValidationError: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53572, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53859, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 53966, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54051, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54137, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54218, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54295, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54388, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54464, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54539, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54612, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54703, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54779, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54854, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 54950, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55046, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55119, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55192, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55267, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 17, 55339, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T02:23:21.608714+00:00", "level": null, "name": "root", "message": "Error in http_request: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 600910, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601055, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601122, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601174, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601228, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601429, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601510, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601569, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601628, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601683, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601730, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601776, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601820, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601867, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601912, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601968, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602011, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602056, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602099, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602142, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77188, "processName": "SpawnProcess-6", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 111, in receive\n    return self.receive_nowait()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 106, in receive_nowait\n    raise WouldBlock\nanyio.WouldBlock\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 124, in receive\n    return receiver.item\nAttributeError: 'MemoryObjectItemReceiver' object has no attribute 'item'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 157, in call_next\n    message = await recv_stream.receive()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 327, in app\n    content = await serialize_response(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 176, in serialize_response\n    raise ResponseValidationError(\nfastapi.exceptions.ResponseValidationError: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 600910, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601055, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601122, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601174, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601228, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601429, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601510, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601569, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601628, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601683, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601730, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601776, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601820, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601867, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601912, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601968, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602011, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602056, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602099, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602142, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "otelSpanID": "b0b8bdb431d1d13b", "otelTraceID": "ec37a0c7afbe5a6c0952f65d4673f332", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 600910, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601055, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601122, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601174, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601228, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601429, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601510, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601569, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601628, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601683, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601730, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601776, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601820, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601867, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601912, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601968, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602011, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602056, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602099, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602142, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "error_type": "ResponseValidationError", "function": "http_request", "request_path": "http://localhost:8080/api/models/text", "request_method": "GET", "stack_trace": [["<frame at 0x10e20fa90, file '/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py', line 47, code _handle_request>", "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py", 28, "_handle_request", ["            response = await call_next(request)\n"], 0], ["<frame at 0x10e20e530, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 163, code call_next>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 163, "call_next", ["                    raise app_exc\n"], 0], ["<frame at 0x10e204790, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py', line 151, code coro>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py", 149, "coro", ["                        await self.app(scope, receive_or_disconnect, send_no_error)\n"], 0], ["<frame at 0x10e615760, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py', line 804, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py", 743, "__call__", ["                await self.app(scope, otel_receive, otel_send)\n"], 0], ["<frame at 0x10f5d3220, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 20, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 20, "__call__", ["                await responder(scope, receive, send)\n"], 0], ["<frame at 0x10f4dd800, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py', line 39, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py", 39, "__call__", ["            await self.app(scope, receive, self.send_with_gzip)\n"], 0], ["<frame at 0x10f4dd9f0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py', line 85, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py", 85, "__call__", ["            await self.app(scope, receive, send)\n"], 0], ["<frame at 0x10f5c6b20, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py', line 62, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py", 62, "__call__", ["        await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n"], 0], ["<frame at 0x10e618530, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10e618530, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x10f3e65b0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 715, code __call__>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 715, "__call__", ["        await self.middleware_stack(scope, receive, send)\n"], 0], ["<frame at 0x10e616010, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 735, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 735, "app", ["                await route.handle(scope, receive, send)\n"], 0], ["<frame at 0x10f5d3400, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 288, code handle>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 288, "handle", ["            await self.app(scope, receive, send)\n"], 0], ["<frame at 0x10f5d35e0, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 76, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 76, "app", ["        await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n"], 0], ["<frame at 0x10e405c90, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 53, "wrapped_app", ["                raise exc\n"], 0], ["<frame at 0x10e405c90, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py', line 63, code wrapped_app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py", 42, "wrapped_app", ["            await app(scope, receive, sender)\n"], 0], ["<frame at 0x10f5dc040, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py', line 73, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py", 73, "app", ["            response = await f(request)\n"], 0], ["<frame at 0x10e616670, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py', line 346, code app>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py", 327, "app", ["                        content = await serialize_response(\n"], 0], ["<frame at 0x10e616d90, file '/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py', line 176, code serialize_response>", "/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py", 176, "serialize_response", ["            raise ResponseValidationError(\n"], 0]]}
{"timestamp": "2024-12-01T02:23:21.622956+00:00", "level": null, "name": "websrc.api.middleware.error_handlers", "message": "Unhandled exception: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 600910, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601055, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601122, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601174, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601228, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601429, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601510, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601569, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601628, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601683, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601730, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601776, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601820, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601867, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601912, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601968, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602011, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602056, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602099, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602142, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/api/middleware/error_handlers.py", "lineno": 120, "funcName": "generic_exception_handler", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 77188, "processName": "SpawnProcess-6", "extra_info": null, "exc_info": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n  |     response_sent.set()\n  |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 763, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    |     response_sent.set()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    |     return await self._handle_request(request, call_next, span)\n    |   File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    |     response = await call_next(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    |     await self.app(scope, otel_receive, otel_send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    |     await self.app(scope, receive, self.send_with_gzip)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 327, in app\n    |     content = await serialize_response(\n    |   File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 176, in serialize_response\n    |     raise ResponseValidationError(\n    | fastapi.exceptions.ResponseValidationError: 20 validation errors:\n    |   {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 600910, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601055, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601122, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601174, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601228, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601429, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601510, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601569, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601628, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601683, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601730, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601776, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601820, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601867, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601912, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601968, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602011, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602056, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602099, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    |   {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602142, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n    | \n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 189, in __call__\n    response_sent.set()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 15, in dispatch\n    return await self._handle_request(request, call_next, span)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/middleware/logging.py\", line 28, in _handle_request\n    response = await call_next(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/opentelemetry/instrumentation/asgi/__init__.py\", line 743, in __call__\n    await self.app(scope, otel_receive, otel_send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 20, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 39, in __call__\n    await self.app(scope, receive, self.send_with_gzip)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 327, in app\n    content = await serialize_response(\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 176, in serialize_response\n    raise ResponseValidationError(\nfastapi.exceptions.ResponseValidationError: 20 validation errors:\n  {'type': 'dict_type', 'loc': ('response', 0), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2.5-1.5B-Instruct', name='Qwen/Qwen2.5-1.5B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=43434252, likes=200, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'chat', 'conversational', 'en', 'arxiv:2407.10671', 'base_model:Qwen/Qwen2.5-1.5B', 'base_model:finetune:Qwen/Qwen2.5-1.5B', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 9, 17, 14, 10, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 600910, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 1), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-1.3b', name='facebook/opt-1.3b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=18765174, likes=160, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 26, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601055, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 2), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='openai-community/gpt2', name='openai-community/gpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=16916736, likes=2388, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601122, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 3), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bigscience/bloomz-560m', name='bigscience/bloomz-560m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=14413980, likes=109, tags=['transformers', 'pytorch', 'tensorboard', 'safetensors', 'bloom', 'text-generation', 'ak', 'ar', 'as', 'bm', 'bn', 'ca', 'code', 'en', 'es', 'eu', 'fon', 'fr', 'gu', 'hi', 'id', 'ig', 'ki', 'kn', 'lg', 'ln', 'ml', 'mr', 'ne', 'nso', 'ny', 'or', 'pa', 'pt', 'rn', 'rw', 'sn', 'st', 'sw', 'ta', 'te', 'tn', 'ts', 'tum', 'tw', 'ur', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu', 'dataset:bigscience/xP3', 'arxiv:2211.01786', 'license:bigscience-bloom-rail-1.0', 'model-index', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 10, 8, 16, 14, 42, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601174, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 4), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', name='bartowski/Meta-Llama-3.1-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=10551093, likes=140, tags=['gguf', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'base_model:meta-llama/Llama-3.1-8B-Instruct', 'base_model:quantized:meta-llama/Llama-3.1-8B-Instruct', 'license:llama3.1', 'endpoints_compatible', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 23, 15, 36, 34, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601228, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': None, 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 5), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='facebook/opt-125m', name='facebook/opt-125m', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6625047, likes=165, tags=['transformers', 'pytorch', 'tf', 'jax', 'opt', 'text-generation', 'en', 'arxiv:2205.01068', 'arxiv:2005.14165', 'license:other', 'autotrain_compatible', 'text-generation-inference', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 5, 11, 8, 25, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601429, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 6), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-8B-Instruct', name='meta-llama/Llama-3.1-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=6618493, likes=3148, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-8B', 'base_model:finetune:meta-llama/Llama-3.1-8B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 18, 8, 56, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601510, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 7), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distributed/optimized-gpt2-1b', name='distributed/optimized-gpt2-1b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=5319926, likes=0, tags=['transformers', 'safetensors', 'gpt_optimized', 'text-generation', 'custom_code', 'arxiv:1910.09700', 'autotrain_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 10, 22, 15, 44, 28, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601569, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 8), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='google/gemma-2-2b', name='google/gemma-2-2b', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=3393442, likes=440, tags=['transformers', 'safetensors', 'gemma2', 'text-generation', 'arxiv:2009.03300', 'arxiv:1905.07830', 'arxiv:1911.11641', 'arxiv:1904.09728', 'arxiv:1905.10044', 'arxiv:1907.10641', 'arxiv:1811.00937', 'arxiv:1809.02789', 'arxiv:1911.01547', 'arxiv:1705.03551', 'arxiv:2107.03374', 'arxiv:2108.07732', 'arxiv:2110.14168', 'arxiv:2009.11462', 'arxiv:2101.11718', 'arxiv:2110.08193', 'arxiv:1804.09301', 'arxiv:2109.07958', 'arxiv:1804.06876', 'arxiv:2103.03874', 'arxiv:2304.06364', 'arxiv:1903.00161', 'arxiv:2206.04615', 'arxiv:2203.09509', 'arxiv:2403.13793', 'license:gemma', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 8, 7, 29, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601628, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 9), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Meta-Llama-3-8B-Instruct', name='meta-llama/Meta-Llama-3-8B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2549447, likes=3650, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'license:llama3', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 17, 9, 35, 12, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601683, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 10), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='distilbert/distilgpt2', name='distilbert/distilgpt2', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2538948, likes=447, tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'coreml', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'dataset:openwebtext', 'arxiv:1910.01108', 'arxiv:2201.08542', 'arxiv:2203.12574', 'arxiv:1910.09700', 'arxiv:1503.02531', 'license:apache-2.0', 'model-index', 'co2_eq_emissions', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601730, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 11), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-70B-Instruct', name='meta-llama/Llama-3.1-70B-Instruct', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2462259, likes=710, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'conversational', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'base_model:meta-llama/Llama-3.1-70B', 'base_model:finetune:meta-llama/Llama-3.1-70B', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 16, 7, 46, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601776, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 12), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='Qwen/Qwen2-0.5B', name='Qwen/Qwen2-0.5B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=2035456, likes=113, tags=['transformers', 'safetensors', 'qwen2', 'text-generation', 'pretrained', 'conversational', 'en', 'license:apache-2.0', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 31, 8, 38, 11, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601820, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 13), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='meta-llama/Llama-3.1-405B', name='meta-llama/Llama-3.1-405B', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1932905, likes=891, tags=['transformers', 'safetensors', 'llama', 'text-generation', 'facebook', 'meta', 'pytorch', 'llama-3', 'en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'arxiv:2204.05149', 'license:llama3.1', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 7, 16, 1, 29, 54, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601867, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 14), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-7B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1930143, likes=10, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-7B-Instruct', 'base_model:quantized:Qwen/Qwen2-7B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 17, 14, 16, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601912, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 15), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', name='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1919406, likes=65, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'conversational', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:mistralai/Mistral-7B-Instruct-v0.3', 'base_model:quantized:mistralai/Mistral-7B-Instruct-v0.3', 'imatrix'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 5, 22, 17, 27, 45, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 601968, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 16), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', name='MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1912642, likes=77, tags=['transformers', 'gguf', 'mistral', 'facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', '16-bit', 'GGUF', 'text-generation', 'en', 'base_model:meta-llama/Meta-Llama-3-8B-Instruct', 'base_model:quantized:meta-llama/Meta-Llama-3-8B-Instruct', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 18, 16, 43, 25, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602011, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 17), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', name='MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1911745, likes=9, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'llama-3', 'llama', 'base_model:Qwen/Qwen2-1.5B-Instruct', 'base_model:quantized:Qwen/Qwen2-1.5B-Instruct', 'region:us', 'imatrix', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 6, 6, 18, 59, 9, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602056, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 18), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', name='MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1905289, likes=56, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'text-generation', 'base_model:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'base_model:quantized:MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1', 'region:us', 'conversational'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 24, 16, 1, 52, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602099, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n  {'type': 'dict_type', 'loc': ('response', 19), 'msg': 'Input should be a valid dictionary', 'input': ModelInfoDTO(id=None, model_id='MaziyarPanahi/WizardLM-2-7B-GGUF', name='MaziyarPanahi/WizardLM-2-7B-GGUF', type=<ModelType.TEXT: 'text'>, is_local=False, is_active=True, description='', downloads=1849175, likes=74, tags=['transformers', 'gguf', 'mistral', 'quantized', '2-bit', '3-bit', '4-bit', '5-bit', '6-bit', '8-bit', 'GGUF', 'safetensors', 'text-generation', 'arxiv:2304.12244', 'arxiv:2306.08568', 'arxiv:2308.09583', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us', 'base_model:microsoft/WizardLM-2-7B', 'base_model:quantized:microsoft/WizardLM-2-7B'], local_path=None, file_hash=None, file_size=None, created_at=datetime.datetime(2024, 4, 15, 16, 51, 17, tzinfo=datetime.timezone.utc), last_used=None, updated_at=datetime.datetime(2024, 12, 1, 2, 23, 21, 602142, tzinfo=datetime.timezone.utc), model_info_metadata={'library_name': 'transformers', 'pipeline_tag': 'text-generation'})}\n", "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:13:24.807581+00:00", "level": null, "name": "src.services.storage_service", "message": "Error storing model: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/storage_service.py", "lineno": 49, "funcName": "store_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 78169, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "a23805d1d4b2e1f0", "otelTraceID": "18ac2178c7bfa058c13a5dce82d15033", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:13:24.809505+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 151, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 78169, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "a23805d1d4b2e1f0", "otelTraceID": "18ac2178c7bfa058c13a5dce82d15033", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:13:24.828530+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 78169, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 131, in download_model\n    metadata = await self.storage.store_model(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 31, in store_model\n    file_hash = await self._calculate_file_hash(source_path)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 83, in _calculate_file_hash\n    async with aiofiles.open(file_path, \"rb\") as f:\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/base.py\", line 63, in __aenter__\n    return await self\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/base.py\", line 59, in __await__\n    self._obj = yield from self._coro.__await__()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/threadpool/__init__.py\", line 92, in _open\n    f = await loop.run_in_executor(executor, cb)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n    result = self.fn(*self.args, **self.kwargs)\nIsADirectoryError: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "otelSpanID": "a23805d1d4b2e1f0", "otelTraceID": "18ac2178c7bfa058c13a5dce82d15033", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:20:57.713404+00:00", "level": null, "name": "src.services.storage_service", "message": "Error storing model: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/storage_service.py", "lineno": 49, "funcName": "store_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82105, "processName": "SpawnProcess-6", "extra_info": null, "otelSpanID": "699ffce60b071c88", "otelTraceID": "e387c5d7d3e859fd3b79b4f2a2faec6c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:20:57.714151+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 155, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82105, "processName": "SpawnProcess-6", "extra_info": null, "otelSpanID": "699ffce60b071c88", "otelTraceID": "e387c5d7d3e859fd3b79b4f2a2faec6c", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:20:57.742300+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82105, "processName": "SpawnProcess-6", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 135, in download_model\n    metadata = await self.storage.store_model(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 31, in store_model\n    file_hash = await self._calculate_file_hash(source_path)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 83, in _calculate_file_hash\n    async with aiofiles.open(file_path, \"rb\") as f:\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/base.py\", line 63, in __aenter__\n    return await self\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/base.py\", line 59, in __await__\n    self._obj = yield from self._coro.__await__()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/threadpool/__init__.py\", line 92, in _open\n    f = await loop.run_in_executor(executor, cb)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n    result = self.fn(*self.args, **self.kwargs)\nIsADirectoryError: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "otelSpanID": "699ffce60b071c88", "otelTraceID": "e387c5d7d3e859fd3b79b4f2a2faec6c", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: [Errno 21] Is a directory: '/tmp/facebook/opt-1.3b_temp'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:23:07.788933+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: [Errno 30] Read-only file system: '/data'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 155, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82303, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "e7d35db9cfbe1f5e", "otelTraceID": "cf162ffac692c2b59a2c0728f42d8b67", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:23:07.806410+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: [Errno 30] Read-only file system: '/data'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82303, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/pathlib.py\", line 1313, in mkdir\n    self._accessor.mkdir(self, mode)\nFileNotFoundError: [Errno 2] No such file or directory: '/data/models'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 128, in download_model\n    temp_dir.mkdir(parents=True, exist_ok=True)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/pathlib.py\", line 1317, in mkdir\n    self.parent.mkdir(parents=True, exist_ok=True)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/pathlib.py\", line 1313, in mkdir\n    self._accessor.mkdir(self, mode)\nOSError: [Errno 30] Read-only file system: '/data'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: [Errno 30] Read-only file system: '/data'", "otelSpanID": "e7d35db9cfbe1f5e", "otelTraceID": "cf162ffac692c2b59a2c0728f42d8b67", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: [Errno 30] Read-only file system: '/data'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:26:51.745363+00:00", "level": null, "name": "src.services.storage_service", "message": "Error storing model: [Errno 21] Is a directory: 'data/models/facebook/opt-1.3b'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/storage_service.py", "lineno": 49, "funcName": "store_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82396, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "1ec711fc7630be5c", "otelTraceID": "03cd63eab57edcef86527da303bf3603", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:26:51.748663+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: [Errno 21] Is a directory: 'data/models/facebook/opt-1.3b'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 154, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82396, "processName": "SpawnProcess-2", "extra_info": null, "otelSpanID": "1ec711fc7630be5c", "otelTraceID": "03cd63eab57edcef86527da303bf3603", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:26:51.780729+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: [Errno 21] Is a directory: 'data/models/facebook/opt-1.3b'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 82396, "processName": "SpawnProcess-2", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 134, in download_model\n    metadata = await self.storage.store_model(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 31, in store_model\n    file_hash = await self._calculate_file_hash(source_path)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 83, in _calculate_file_hash\n    async with aiofiles.open(file_path, \"rb\") as f:\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/base.py\", line 63, in __aenter__\n    return await self\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/base.py\", line 59, in __await__\n    self._obj = yield from self._coro.__await__()\n  File \"/Users/joshreed/Code/LocalGPU/.venv/lib/python3.9/site-packages/aiofiles/threadpool/__init__.py\", line 92, in _open\n    f = await loop.run_in_executor(executor, cb)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n    result = self.fn(*self.args, **self.kwargs)\nIsADirectoryError: [Errno 21] Is a directory: 'data/models/facebook/opt-1.3b'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: [Errno 21] Is a directory: 'data/models/facebook/opt-1.3b'", "otelSpanID": "1ec711fc7630be5c", "otelTraceID": "03cd63eab57edcef86527da303bf3603", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: [Errno 21] Is a directory: 'data/models/facebook/opt-1.3b'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:34:36.323335+00:00", "level": null, "name": "src.services.storage_service", "message": "Error storing model: module 'datetime' has no attribute 'UTC'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/storage_service.py", "lineno": 72, "funcName": "store_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 83386, "processName": "SpawnProcess-5", "extra_info": null, "otelSpanID": "a3043f871f074ad0", "otelTraceID": "7e6abd53e98db0f42457662333abe698", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:34:36.377349+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: module 'datetime' has no attribute 'UTC'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 154, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 83386, "processName": "SpawnProcess-5", "extra_info": null, "otelSpanID": "a3043f871f074ad0", "otelTraceID": "7e6abd53e98db0f42457662333abe698", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:34:36.771417+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: module 'datetime' has no attribute 'UTC'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 83386, "processName": "SpawnProcess-5", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 134, in download_model\n    metadata = await self.storage.store_model(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 54, in store_model\n    created_at=datetime.datetime.now(datetime.UTC)\nAttributeError: module 'datetime' has no attribute 'UTC'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: module 'datetime' has no attribute 'UTC'", "otelSpanID": "a3043f871f074ad0", "otelTraceID": "7e6abd53e98db0f42457662333abe698", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: module 'datetime' has no attribute 'UTC'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:38:02.539301+00:00", "level": null, "name": "src.services.storage_service", "message": "Error storing model: ModelMetadata() takes no arguments", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/storage_service.py", "lineno": 72, "funcName": "store_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 83909, "processName": "SpawnProcess-9", "extra_info": null, "otelSpanID": "a2dbebf8ec30ba62", "otelTraceID": "c9b834fa19b21bea92224b1942cc4124", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:38:02.578397+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: ModelMetadata() takes no arguments", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 155, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 83909, "processName": "SpawnProcess-9", "extra_info": null, "otelSpanID": "a2dbebf8ec30ba62", "otelTraceID": "c9b834fa19b21bea92224b1942cc4124", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:38:02.701634+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: ModelMetadata() takes no arguments", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 83909, "processName": "SpawnProcess-9", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 135, in download_model\n    metadata = await self.storage.store_model(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/storage_service.py\", line 51, in store_model\n    return ModelMetadata(\nTypeError: ModelMetadata() takes no arguments\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: ModelMetadata() takes no arguments", "otelSpanID": "a2dbebf8ec30ba62", "otelTraceID": "c9b834fa19b21bea92224b1942cc4124", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: ModelMetadata() takes no arguments", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:44:33.885998+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model files: 'ModelDiscoveryService' object has no attribute '_check_disk_space'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 200, "funcName": "_download_model_files", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84349, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "17f5dee0209df917", "otelTraceID": "da79519e6d6e8dffdba4649704fe4fd6", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:44:33.931259+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: 'ModelDiscoveryService' object has no attribute '_check_disk_space'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 155, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84349, "processName": "SpawnProcess-1", "extra_info": null, "otelSpanID": "17f5dee0209df917", "otelTraceID": "da79519e6d6e8dffdba4649704fe4fd6", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:44:33.946808+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: 'ModelDiscoveryService' object has no attribute '_check_disk_space'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84349, "processName": "SpawnProcess-1", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 132, in download_model\n    await self._download_model_files(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 189, in _download_model_files\n    if not self._check_disk_space(model_id):\nAttributeError: 'ModelDiscoveryService' object has no attribute '_check_disk_space'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: 'ModelDiscoveryService' object has no attribute '_check_disk_space'", "otelSpanID": "17f5dee0209df917", "otelTraceID": "da79519e6d6e8dffdba4649704fe4fd6", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: 'ModelDiscoveryService' object has no attribute '_check_disk_space'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:47:28.362094+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 385, "funcName": "_check_disk_space", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84506, "processName": "SpawnProcess-7", "extra_info": null, "otelSpanID": "4b48592467491cb6", "otelTraceID": "44e34c3b2ad03a3749a6d460d2f5b50e", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:47:28.363149+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model files: __init__() got an unexpected keyword argument 'source_class'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 201, "funcName": "_download_model_files", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84506, "processName": "SpawnProcess-7", "extra_info": null, "otelSpanID": "4b48592467491cb6", "otelTraceID": "44e34c3b2ad03a3749a6d460d2f5b50e", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:47:28.363983+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: __init__() got an unexpected keyword argument 'source_class'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 156, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84506, "processName": "SpawnProcess-7", "extra_info": null, "otelSpanID": "4b48592467491cb6", "otelTraceID": "44e34c3b2ad03a3749a6d460d2f5b50e", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:47:28.379877+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: __init__() got an unexpected keyword argument 'source_class'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84506, "processName": "SpawnProcess-7", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 369, in _check_disk_space\n    card_data = model_info.card_data.model_dump()\nAttributeError: 'ModelCardData' object has no attribute 'model_dump'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 133, in download_model\n    await self._download_model_files(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 190, in _download_model_files\n    if not self._check_disk_space(model_id):\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 386, in _check_disk_space\n    raise NotEnoughDiskSpaceError(f\"Insufficient disk space for model download\", source_class=self.__class__.__name__)\nTypeError: __init__() got an unexpected keyword argument 'source_class'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: __init__() got an unexpected keyword argument 'source_class'", "otelSpanID": "4b48592467491cb6", "otelTraceID": "44e34c3b2ad03a3749a6d460d2f5b50e", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: __init__() got an unexpected keyword argument 'source_class'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:48:20.668483+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 385, "funcName": "_check_disk_space", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84567, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "dd06b8fadb865d72", "otelTraceID": "e1188ad1ed377981204c9557277dd854", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:48:20.669153+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model files: Insufficient disk space for model download", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 201, "funcName": "_download_model_files", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84567, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "dd06b8fadb865d72", "otelTraceID": "e1188ad1ed377981204c9557277dd854", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:48:20.669935+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: Insufficient disk space for model download", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 156, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84567, "processName": "SpawnProcess-10", "extra_info": null, "otelSpanID": "dd06b8fadb865d72", "otelTraceID": "e1188ad1ed377981204c9557277dd854", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:48:20.684821+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: Insufficient disk space for model download", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84567, "processName": "SpawnProcess-10", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 369, in _check_disk_space\n    card_data = model_info.card_data.model_dump()\nAttributeError: 'ModelCardData' object has no attribute 'model_dump'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 133, in download_model\n    await self._download_model_files(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 190, in _download_model_files\n    if not self._check_disk_space(model_id):\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 386, in _check_disk_space\n    raise NotEnoughDiskSpaceError(\"Insufficient disk space for model download\")\nexceptions.exceptions.NotEnoughDiskSpaceError: Insufficient disk space for model download\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: Insufficient disk space for model download", "otelSpanID": "dd06b8fadb865d72", "otelTraceID": "e1188ad1ed377981204c9557277dd854", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: Insufficient disk space for model download", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:49:48.350403+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 402, "funcName": "_check_disk_space", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84671, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "b5740b73f8587c0b", "otelTraceID": "bc6c9b7ccad23d71f47008df2d24a601", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:49:48.350819+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model files: Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 201, "funcName": "_download_model_files", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84671, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "b5740b73f8587c0b", "otelTraceID": "bc6c9b7ccad23d71f47008df2d24a601", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:49:48.351180+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 156, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84671, "processName": "SpawnProcess-11", "extra_info": null, "otelSpanID": "b5740b73f8587c0b", "otelTraceID": "bc6c9b7ccad23d71f47008df2d24a601", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:49:48.381951+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84671, "processName": "SpawnProcess-11", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 375, in _check_disk_space\n    card_data = model_info.card_data.model_dump()\nAttributeError: 'ModelCardData' object has no attribute 'model_dump'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 133, in download_model\n    await self._download_model_files(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 190, in _download_model_files\n    if not self._check_disk_space(model_id):\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 403, in _check_disk_space\n    raise NotEnoughDiskSpaceError(f\"Error checking disk space: {e}\")\nexceptions.exceptions.NotEnoughDiskSpaceError: Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "otelSpanID": "b5740b73f8587c0b", "otelTraceID": "bc6c9b7ccad23d71f47008df2d24a601", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: Error checking disk space: 'ModelCardData' object has no attribute 'model_dump'", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:52:52.027574+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Empty file found: data/models/facebook/opt-1.3b/.cache/huggingface/download/tf_model.h5.lock", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 439, "funcName": "_verify_download", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 13080752128, "threadName": "ThreadPoolExecutor-2_0", "process": 84706, "processName": "SpawnProcess-12", "extra_info": null, "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:52:52.131235+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model files: Model download verification failed", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 201, "funcName": "_download_model_files", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84706, "processName": "SpawnProcess-12", "extra_info": null, "otelSpanID": "265cd76eec13629e", "otelTraceID": "2ab947744a34c843274c2a0207a1d5b5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:52:52.131408+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: Model download verification failed", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 156, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84706, "processName": "SpawnProcess-12", "extra_info": null, "otelSpanID": "265cd76eec13629e", "otelTraceID": "2ab947744a34c843274c2a0207a1d5b5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:52:52.137768+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: Model download verification failed", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84706, "processName": "SpawnProcess-12", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 133, in download_model\n    await self._download_model_files(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 195, in _download_model_files\n    await loop.run_in_executor(\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 197, in <lambda>\n    lambda: self._download_model_sync(model_id, model_path)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 224, in _download_model_sync\n    raise RuntimeError(\"Model download verification failed\")\nRuntimeError: Model download verification failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: Model download verification failed", "otelSpanID": "265cd76eec13629e", "otelTraceID": "2ab947744a34c843274c2a0207a1d5b5", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: Model download verification failed", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
{"timestamp": "2024-12-01T03:59:56.159312+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Empty file found: data/models/facebook/opt-1.3b/.cache/huggingface/download/tf_model.h5.lock", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 448, "funcName": "_verify_download", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 12960673792, "threadName": "ThreadPoolExecutor-2_0", "process": 84936, "processName": "SpawnProcess-13", "extra_info": null, "otelSpanID": "0", "otelTraceID": "0", "otelTraceSampled": false, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:59:56.255821+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model files: Model download verification failed", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 201, "funcName": "_download_model_files", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84936, "processName": "SpawnProcess-13", "extra_info": null, "otelSpanID": "aad50031db8f8568", "otelTraceID": "cd9225094ae7ede20697317bdfbb71c5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:59:56.255990+00:00", "level": null, "name": "ModelDiscoveryService", "message": "Failed to download model: Model download verification failed", "pathname": "/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py", "lineno": 156, "funcName": "download_model", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84936, "processName": "SpawnProcess-13", "extra_info": null, "otelSpanID": "aad50031db8f8568", "otelTraceID": "cd9225094ae7ede20697317bdfbb71c5", "otelTraceSampled": true, "otelServiceName": "locaLLM"}
{"timestamp": "2024-12-01T03:59:56.259864+00:00", "level": null, "name": "root", "message": "Error in websrc.api.routes.models.download_model: 500: Model download verification failed", "pathname": "/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py", "lineno": 146, "funcName": "_handle_error", "request_info": null, "response_info": null, "trace_id": null, "span_id": null, "thread": 8223257152, "threadName": "MainThread", "process": 84936, "processName": "SpawnProcess-13", "extra_info": null, "exc_info": "Traceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 59, in download_model\n    await model_service.download_model(request.model_id, ModelType(request.type))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 133, in download_model\n    await self._download_model_files(model_id, str(temp_path))\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 195, in _download_model_files\n    await loop.run_in_executor(\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 197, in <lambda>\n    lambda: self._download_model_sync(model_id, model_path)\n  File \"/Users/joshreed/Code/LocalGPU/src/services/model_discovery_service.py\", line 224, in _download_model_sync\n    raise RuntimeError(\"Model download verification failed\")\nRuntimeError: Model download verification failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/joshreed/Code/LocalGPU/websrc/config/logging_manager.py\", line 108, in wrapper\n    result = await func(*args, **kwargs)\n  File \"/Users/joshreed/Code/LocalGPU/websrc/api/routes/models.py\", line 62, in download_model\n    raise HTTPException(status_code=500, detail=str(e))\nfastapi.exceptions.HTTPException: 500: Model download verification failed", "otelSpanID": "aad50031db8f8568", "otelTraceID": "cd9225094ae7ede20697317bdfbb71c5", "otelTraceSampled": true, "otelServiceName": "locaLLM", "error": "500: Model download verification failed", "error_type": "HTTPException", "function": "websrc.api.routes.models.download_model", "status_code": 500}
